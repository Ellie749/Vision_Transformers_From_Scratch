# Vision Transformers from Scratch

This repository contains a from-scratch implementation of the Vision Transformer (ViT) architecture using Tensorflow. It walks through the core building blocks such as positional encoding, patch embedding, multi-head attention, and classification head.

## ğŸ“ Project Structure
VISION_TRANSFORMERS_FROM_SCRATCH <br>
| â”œâ”€â”€ examples<br>
â”‚ â”œâ”€â”€ src <br>
â”‚   â”œâ”€â”€ data_pipeline <br>
â”‚   â”‚   â””â”€â”€ load_dataset.py # Functions to load and preprocess datasets <br>
â”‚   â”œâ”€â”€ model<br>
â”‚   |    â””â”€â”€ train.py # Functions run experiments <br>
â”‚   â”œâ”€â”€ network<br>
â”‚   â”‚   â”œâ”€â”€ architecture.py # Creating and assembling ViT network architecture<br>
â”‚   â”‚   |   positional_encoding.py # Positional encoding for ViT <br>
â”‚   â”‚   â””â”€â”€ mlp.py<br>
â”‚   â”œâ”€â”€  visualization<br>
â”‚   â”‚   â””â”€â”€ utils.py # visualizing train metrics<br>
â”‚   â”œâ”€â”€ weights/ # Directory to save trained model weights <br>
|   â”œâ”€â”€ experiments.ipynb # Notebook for quick experimentation<br>
|   â”œâ”€â”€ project.p # main training code<br>
| â”œâ”€â”€ application.py <br>
| â”œâ”€â”€ config.ini # Configuration file <br>
| â”œâ”€â”€ README.md # You're here!<br>
| â””â”€â”€ requirement.txt<br>



## ğŸš€ Features

- ğŸ”¢ Patch embedding and positional encoding
- ğŸ§  Transformer blocks (multi-head attention, MLP)
- ğŸ“¦ Data pipeline for loading and preprocessing image datasets
- ğŸ§ª Jupyter Notebook for testing components interactively
- ğŸ·ï¸ Modular codebase for easy extension

## ğŸ› ï¸ Requirements

Install dependencies via:

```bash
pip install -r requirements.txt
```

ğŸ“Š Dataset
Currently supports image classification datasets like CIFAR-100. You can modify load_dataset.py to plug in other datasets.

ğŸ§  TODO