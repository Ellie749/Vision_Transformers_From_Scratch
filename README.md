# Vision Transformers from Scratch

This repository contains a from-scratch implementation of the Vision Transformer (ViT) architecture using Tensorflow. It walks through the core building blocks such as positional encoding, patch embedding, multi-head attention, and classification head.

## ğŸ“ Project Structure
VISION_TRANSFORMERS_FROM_SCRATCH <br>
|   â”œâ”€â”€ examples<br>
â”‚   â”œâ”€â”€ src <br>
â”‚       â”œâ”€â”€ data_pipeline <br>
â”‚       â”‚   â””â”€â”€ load_dataset.py # Functions to load and preprocess datasets <br>
â”‚       â”œâ”€â”€ model<br>
â”‚       |       â””â”€â”€ train.py # Functions run experiments <br>
â”‚       â”œâ”€â”€ network<br>
â”‚       â”‚   â”œâ”€â”€ architecture.py # Creating and assembling ViT network architecture<br>
â”‚       â”‚   |   positional_encoding.py # Positional encoding for ViT <br>
â”‚       â”‚   â””â”€â”€ mlp.py<br>
â”‚       â”œâ”€â”€  visualization<br>
â”‚       â”‚   â””â”€â”€ utils.py # visualizing train metrics<br>
â”‚       â”œâ”€â”€ weights/ # Directory to save trained model weights <br>
â”‚       â”œâ”€â”€ experiments.ipynb # Notebook for quick experimentation<br>
â”‚       â”œâ”€â”€ project.p # main training code<br>
â”‚   â”œâ”€â”€ application.py <br>
â”‚   â”œâ”€â”€ config.ini # Configuration file <br>
â”‚   â”œâ”€â”€ README.md # You're here!<br>
â””â”€â”€ requirement.txt<br>


## Requirements

Install dependencies via:

```bash
pip install -r requirements.txt
```

Dataset
Currently supports image classification datasets like CIFAR-100. You can modify load_dataset.py to plug in other datasets.

ğŸ§  TODO
 complete training on 150 epochs
 change weight directory
 add inference
 add more regularizations
 add unit tests

ğŸ“ References
[An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)